* A Crash Course in Bayesian Inference
** Confidence Set
Confidence "Set" for θ
|---------+------+-----|
| (Y₁,Y₂) | θ-1  | θ+1 |
|---------+------+-----|
| θ-1     |θ-2   |θ    |
| θ+1     |θ     |θ    |
|---------+------+-----|

** The 0-1 Loss
  
  min(δ) ∫L(θ,δ)p(θ|Y)dθ
  
  Suppose Y = 1
  
  p(θ = 0 | Y = 1) = 0.358
  p(θ = 1 | Y = 1) = 0.642
  
  what happens if δ = 0?
  E[L(θ,δ=0)] = 0 × p(θ=0|Y=1) + 1 × p(θ=1|Y=1) 
              = p(θ = 1|Y = 1)
  what happens if δ = 1?
  E[L(θ,δ=1)] = 1 × p(θ=0|Y=1) + 0 × p(θ=1|Y=1) 
              = p(θ = 0|Y = 1)  

  Since p(θ=0|Y=1) < p(θ=1|Y=1)
  choose δ = 1!!

** Quadratic Loss  
  E[(θ-δ)²|Yᵀ] = ∫(θ-δ)²p(θ|Yᵀ)dθ
               = ∫(θ² - 2δθ + δ²)p(θ|Yᵀ)dθ
  
  Taking first order condition
  
  2δ = 2∫θp(θ|Yᵀ)dθ
  => δ = E[θ|Yᵀ]
                 
** Hypothesis Testing 
  δ = 1 ("Accept the Null")

  Four Cases:
  1. δ = 1, θ ∈ Θ₀ (good!): Loss = 0
  2. δ = 1, θ ∈ Θ₁ (bad!) : Loss = a₁
  3. δ = 0, θ ∈ Θ₀ (bad!) : Loss = a₀
  4. δ = 0, θ ∈ Θ₁ (good!): Loss = 0
  
  E[L(θ,δ=1)] = 0 × P(θ∈Θ₀) + a₁×P(θ∈Θ₁)

  E[L(θ,δ=0)] = a₀ × P(θ∈Θ₀) + 0×P(θ∈Θ₁)
  
** Model Selection  
   Encompassing model has two parameters α and θ
   
   M₁ : θ = 0, M₂ : θ ≠ 0

   p(M₁|Y) vs. p(M₂|Y)
   
   p(M₁|Y) = p(Y|M₁)p(M₁) / p(Y)

   p(M₂|Y) = p(Y|M₂)p(M₂) / p(Y) 

   p(M₁|Y) / p(M₂|Y) = p(Y|M₁)p(M₁)/(p(Y|M₂)p(M₂))

   p(M₁) and p(M₂) are user supplied
   
   p(Y|M₁) = ∫p(Y|α,θ=0)p(α)dα
   p(Y|M₂) = ∫p(Y|α,θ)p(α,θ)dαdθ

* Solving DSGE Models  
** Local Approximation  
   yₜ = f(yₜ₋₁, σεₜ)
   
   guess
   yₜ = yₜ⁰ + σ yₜ¹ + o(σ)
   
   At steady state

** LRE   
   
   yₜ = 1/θ * Eₜ[yₜ₊₁] + εₜ
   
   ξₜ = Eₜ[yₜ₊₁] and ηₜ = yₜ - ξₜ₋₁

   thus:
   ηₜ + ξₜ₋₁ = 1/θ ξₜ + εₜ  ⇔
   ξₜ = θξₜ₋₁ - θεₜ + θηₜ
   
   
   if θ > 1

* Kalman Filter   
  
** Iterating Through
  Let's from Time 0 to Time 1
  
  s₀|{no data} ~ N(A₀, P₀)
  
  s₁ = C + Ts₀ + Rεₜ

  => s₁ ~ N(A₁₀, P₁₀}
 
  A₁₀ = C + TA₀
  P₁₀ = T P₀ T' + RQR'
  
  Now consider
