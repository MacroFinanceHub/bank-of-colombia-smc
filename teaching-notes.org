* A Crash Course in Bayesian Inference
** Confidence Set
Confidence "Set" for θ
|---------+------+-----|
| (Y₁,Y₂) | θ-1  | θ+1 |
|---------+------+-----|
| θ-1     |θ-2   |θ    |
| θ+1     |θ     |θ    |
|---------+------+-----|

** The 0-1 Loss
  
  min(δ) ∫L(θ,δ)p(θ|Y)dθ
  
  Suppose Y = 1
  
  p(θ = 0 | Y = 1) = 0.358
  p(θ = 1 | Y = 1) = 0.642
  
  what happens if δ = 0?
  E[L(θ,δ=0)] = 0 × p(θ=0|Y=1) + 1 × p(θ=1|Y=1) 
              = p(θ = 1|Y = 1)
  what happens if δ = 1?
  E[L(θ,δ=1)] = 1 × p(θ=0|Y=1) + 0 × p(θ=1|Y=1) 
              = p(θ = 0|Y = 1)  

  Since p(θ=0|Y=1) < p(θ=1|Y=1)
  choose δ = 1!!

** Quadratic Loss  
  E[(θ-δ)²|Yᵀ] = ∫(θ-δ)²p(θ|Yᵀ)dθ
               = ∫(θ² - 2δθ + δ²)p(θ|Yᵀ)dθ
  
  Taking first order condition
  
  2δ = 2∫θp(θ|Yᵀ)dθ
  => δ = E[θ|Yᵀ]
                 
** Hypothesis Testing 
  δ = 1 ("Accept the Null")

  Four Cases:
  1. δ = 1, θ ∈ Θ₀ (good!): Loss = 0
  2. δ = 1, θ ∈ Θ₁ (bad!) : Loss = a₁
  3. δ = 0, θ ∈ Θ₀ (bad!) : Loss = a₀
  4. δ = 0, θ ∈ Θ₁ (good!): Loss = 0
  
  E[L(θ,δ=1)] = 0 × P(θ∈Θ₀) + a₁×P(θ∈Θ₁)

  E[L(θ,δ=0)] = a₀ × P(θ∈Θ₀) + 0×P(θ∈Θ₁)
  
** Model Selection  
   Encompassing model has two parameters α and θ
   
   M₁ : θ = 0, M₂ : θ ≠ 0

   p(M₁|Y) vs. p(M₂|Y)
   
   p(M₁|Y) = p(Y|M₁)p(M₁) / p(Y)

   p(M₂|Y) = p(Y|M₂)p(M₂) / p(Y) 

   p(M₁|Y) / p(M₂|Y) = p(Y|M₁)p(M₁)/(p(Y|M₂)p(M₂))

   p(M₁) and p(M₂) are user supplied
   
   p(Y|M₁) = ∫p(Y|α,θ=0)p(α)dα
   p(Y|M₂) = ∫p(Y|α,θ)p(α,θ)dαdθ

* Solving DSGE Models  
** Local Approximation  
   yₜ = f(yₜ₋₁, σεₜ)
   
   guess
   yₜ = yₜ⁰ + σ yₜ¹ + o(σ)
   
   At steady state

** LRE 
   
   yₜ = 1/θ * Eₜ[yₜ₊₁] + εₜ
   
   ξₜ = Eₜ[yₜ₊₁] and ηₜ = yₜ - ξₜ₋₁

   thus:
   ηₜ + ξₜ₋₁ = 1/θ ξₜ + εₜ  ⇔
   ξₜ = θξₜ₋₁ - θεₜ + θηₜ
   
   
   if θ > 1

* Kalman Filter   
  
** Iterating Through
  Let's from Time 0 to Time 1
  
  s₀|{no data} ~ N(A₀, P₀)
  
  s₁ = C + Ts₀ + Rε₁

  => s₁ ~ N(A₁₀, P₁₀}
 
  A₁₀ = C + TA₀
  P₁₀ = T P₀ T' + RQR'
  
  Now consider
  y₁ = D + Z s₁ + η₁ 
  
  haty = D+ZA₁₀ 
  F₁₀ = Z P₁₀ Z' + H
  
  y₁|{no data} ~ N(haty, F₁₀) => likelihood!
  

  y₁ = D + Z(C + Ts₀ + Rε₁) + η₁ 
     = D + ZC + ZTs₀ + ZRε₁ + η₁
  s₁ = C + Ts₀ + Rε₁     
  
  VAR[y₁,s₁] = Z P₁₀
  
  A₁ = A₁₀ + P₁₀Z'F₁₀⁻¹(y₁ - haty)
  P₁ = P₁₀ - P₁₀Z'F₁₀⁻¹ZP₁₀
  
  s₁|Y¹ ~ N(A₁,P₁)
  
** Invariant Distribution  
   
   sₜ = Tsₜ₋₁ + Rεₜ is stationary
   
   unconditional mean = 0 
     ( with constant = (I - T)⁻¹C  )

   unconditional variance 
   sₜsₜ' = (Tsₜ₋₁+ Rεₜ)(Tsₜ₋₁+ Rεₜ)'
        = Tsₜ₋₁sₜ₋₁'T' + Rεₜεₜ'R' + cross
        
   => 
   VAR[sₜ] = T VAR[sₜ₋₁] T' + RQR'
   
   P₀ = VAR[sₜ] = VAR[sₜ₋₁]
   
   P₀ = TP₀T' + RQR
   
** Missing Data
   
   (D,Z,H) can time varying!
   
   Imagine we have 3 series
   n_y = 3
   
   but at some period t, we 
   only observe 2 of the series
   
   imagine that we observe the
   2nd and 3rd 
   
        [0 1 0]
   Mt = [0 0 1]
   
   Dt = Mt * D 
   Zt = Mt * Z
   Ht = Mt * H * Mt'
   
** Smoothing   
   
   filter delivers p(sₜ | Yᵗ)
   
   but we might want 
   
   p(sₜ | Yᵀ) [smoothed distribution]
   
   draw random variables from
   p(sₜ | Yᵀ)
   
   that's called "simulation smoother"
   
* MH   
** Simple Example  
   
   1. Case 1: θⁱ⁻¹ = τ₁. What is 
      the probability that 
      the proposal is τ₁? 
      
      The answer is q.
      
      What is probability that is 
      accepted?
      
      α(τ₁|τ₁) = min{1, [π₁/q]/[π₁/q]}
              = 1
              
      What is the probability that
      I propose τ₂?
      
      The answer is 1-q
      
      α(τ₂|τ₁) = min{1,[π₂/(1-q)]/[π₁/(1-q)]}
              = 1

   2. Case 2: θⁱ⁻¹ = τ₂.  What is the 
      probability that the 
      proposal is τ₁?
      
      The answer is 1-q
      
      What is the probability that
      is accepted?
      
      α(τ₁|τ₂) = min{1, [π₁/(1-q)]/
                       [π₂/(1-q)]}
              = min{1, π₁/π₂}
              = π₁ / π₂
              
   What is the probability that I transition
   from τ₁ to τ₁? 
   
q       Probability(Propose τ₁|τ₁) x
1       Probability that I accept that
+       +
(1-q)   Probability(Propose τ₂|τ₁) x
0       Probability that I reject
   
   q x 1 + (1-q) x 0 = q [=k11]
   
